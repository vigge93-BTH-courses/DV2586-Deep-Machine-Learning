https://github.com/stopwords-iso/stopwords-sv
https://stackoverflow.com/questions/42742810/speed-up-millions-of-regex-replacements-in-python-3/42747503#42747503
https://www.tensorflow.org/tutorials/text/word2vec#model_and_training
https://www.tensorflow.org/text/guide/word_embeddings
https://leimao.github.io/blog/Byte-Pair-Encoding/
https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b


https://keras.io/api/keras_nlp/

Transform dataset:
1hs

BPE:
14h

Tokenize:
7h

Embedding train data:
6min

Embedder training:
20min

CountVectorizer:
MemoryError: Unable to allocate 4.20 PiB for an array with shape (193900721, 3049430) and data type int64
