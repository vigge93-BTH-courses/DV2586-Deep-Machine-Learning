{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydot\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from keras import models\n",
    "from keras.layers import (Activation, Add, AveragePooling2D,\n",
    "                          BatchNormalization, Concatenate, Conv2D, Dense,\n",
    "                          Flatten, GlobalAveragePooling2D, Input, MaxPooling2D,\n",
    "                          Softmax)\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x**2 + y**2 + x*(y + 2) + math.cos(3*x)\n",
    "\n",
    "def dfdx(x, y):\n",
    "    return 2*x + y + 2 - 3*math.sin(3*x)\n",
    "\n",
    "def dfdy(x, y):\n",
    "    return 2*y + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GDPoint():\n",
    "    x: int\n",
    "    y: int\n",
    "    z: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, lr, steps=20):\n",
    "    data_points = []\n",
    "    for _ in range(steps):\n",
    "        z = f(x, y)\n",
    "        data_points.append(GDPoint(x, y, z))\n",
    "        dx = dfdx(x, y)\n",
    "        dy = dfdy(x, y)\n",
    "        x -= dx * lr\n",
    "        y -= dy * lr\n",
    "    return x, y, data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  []\n",
    "for x_init in range(-10, 10):\n",
    "    for y_init in range(-10, 10):\n",
    "        x_final, y_final, values = gradient_descent(x_init, y_init, 0.1, 100)\n",
    "        results.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{x_final=}, {y_final=}, {values[-1]=}')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "for result in results:\n",
    "    zs = [d.z for d in result[95:]]\n",
    "    ax.plot(zs)\n",
    "ax.set_title(\"Gradient descent with all integer start values $x, y \\in [-10, 10)$\\n for iteration 95 to 100\")\n",
    "plt.ylabel(\"Function value\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.xticks(ticks=range(5), labels=range(96, 101))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVGG19():\n",
    "    L2 = 0.0005\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(64, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2), input_shape=(32, 32, 3))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "\n",
    "    model = models.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=x\n",
    "    )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691\n",
    "def resnetIdentity(x, filters, L2):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    x = Conv2D(f1, kernel_size=1, padding='valid', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(f1, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(f2, kernel_size=1, padding='valid')(x)\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(tf.keras.activations.relu)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def resnetConv(x, s, filters, L2):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "    x = Conv2D(f1, kernel_size=1, strides=s, padding='valid', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(f1, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(f2, kernel_size=1, padding='valid', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x_skip = Conv2D(f2, kernel_size=1, strides=s, padding='valid', kernel_regularizer=tf.keras.regularizers.l2(L2))(x_skip)\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(tf.keras.activations.relu)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def getResnet50():\n",
    "    L2 = 0.001\n",
    "    inp = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "    x = resnetConv(x, s=1, filters=(64,256), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(64,256), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(64,256), L2=L2)\n",
    "    \n",
    "    x = resnetConv(x, s=2, filters=(128, 512), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(128, 512), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(128, 512), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(128, 512), L2=L2)\n",
    "    \n",
    "    x = resnetConv(x, s=2, filters=(256, 1024), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(256, 1024), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(256, 1024), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(256, 1024), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(256, 1024), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(256, 1024), L2=L2)\n",
    "    \n",
    "    x = resnetConv(x, s=2, filters=(512, 2048), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(512, 2048), L2=L2)\n",
    "    x = resnetIdentity(x, filters=(512, 2048), L2=L2)\n",
    "    \n",
    "    x = AveragePooling2D(pool_size=2, padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(\n",
    "        inputs=inp,\n",
    "        outputs=x\n",
    "    )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://towardsdatascience.com/creating-densenet-121-with-tensorflow-edbc08a956d8\n",
    "def denseBlock(x, repetitions):\n",
    "    for _ in range(repetitions):\n",
    "        y = Conv2D(128, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        x = Concatenate()((y, x))\n",
    "    return x\n",
    "\n",
    "def getDenseNet():\n",
    "    inp = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = denseBlock(x, 6)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = denseBlock(x, 12)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = denseBlock(x, 24)\n",
    "    \n",
    "    x = Conv2D(512, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = denseBlock(x, 16)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(\n",
    "        inputs=inp,\n",
    "        outputs=out\n",
    "    )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpconvLayer(x, L2):\n",
    "    x = Conv2D(192, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(160, kernel_size=1, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(96, kernel_size=1, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def getNiN():\n",
    "    L2 = 0.0001\n",
    "    inp = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(128, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2), input_shape=(32, 32, 3))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = mlpconvLayer(x, L2)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = mlpconvLayer(x, L2)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = mlpconvLayer(x, L2)\n",
    "    \n",
    "    x = Conv2D(10, kernel_size=1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Softmax()(x)\n",
    "    \n",
    "    model = models.Model(\n",
    "        inputs=inp,\n",
    "        outputs=x\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = getVGG19()\n",
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = getResnet50()\n",
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet = getDenseNet()\n",
    "denseNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NiN = getNiN()\n",
    "NiN.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModel(model):\n",
    "    return SVG(model_to_dot(\n",
    "        model, show_shapes=True, show_layer_activations=True, rankdir='TB',\n",
    "        expand_nested=False, dpi=60, subgraph=False\n",
    "    ).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotModel(vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotModel(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotModel(denseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotModel(NiN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation = image_dataset_from_directory('250000_Final',\n",
    "                                      label_mode='categorical',\n",
    "                                      image_size=(32, 32),\n",
    "                                      validation_split=0.2,\n",
    "                                      shuffle=True,\n",
    "                                      seed=42,\n",
    "                                      batch_size=128,\n",
    "                                      subset='both')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in training.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(np.argmax((labels[i])))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(images,labels):\n",
    "    images = images/255.\n",
    "    return images,labels\n",
    "\n",
    "training = training.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation = validation.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "training = training.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "validation = validation.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"models/vgg19/cp-{epoch:02d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1)\n",
    "vgg19_history = vgg19.fit(training, epochs=10, batch_size=128, validation_data=validation, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"models/resnet50/cp-{epoch:02d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1)\n",
    "resnet50_history = resnet50.fit(training, epochs=10, batch_size=128, validation_data=validation, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"models/densenet/cp-{epoch:02d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1)\n",
    "densenet_history = denseNet.fit(training, epochs=10, batch_size=128, validation_data=validation, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"models/NiN/cp-{epoch:02d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1)\n",
    "nin_history = NiN.fit(training, epochs=10, batch_size=128, validation_data=validation, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg19_history.history['loss'], label='Training loss')\n",
    "plt.plot(vgg19_history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Training and validation loss for VGG19')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.plot(vgg19_history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(vgg19_history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and validation accuracy for VGG19')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resnet50_history.history['loss'], label='Training loss')\n",
    "plt.plot(resnet50_history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Training and validation loss for ResNet50')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.plot(resnet50_history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(resnet50_history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and validation accuracy for ResNet50')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(densenet_history.history['loss'], label='Training loss')\n",
    "plt.plot(densenet_history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Training and validation loss for DenseNet121')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.plot(densenet_history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(densenet_history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and validation accuracy for DenseNet121')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nin_history.history['loss'], label='Training loss')\n",
    "plt.plot(nin_history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Training and validation loss for NiN')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.plot(nin_history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(nin_history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and validation accuracy for NiN')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.yticks([x/10 for x in range(2, 11)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get F1-score and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_predictions = vgg19.predict(validation)\n",
    "resnet50_predictions = resnet50.predict(validation)\n",
    "densenet_predictions = denseNet.predict(validation)\n",
    "NiN_predictions = NiN.predict(validation)\n",
    "vgg19_predictions = list(np.argmax(vgg19_predictions, axis=1))\n",
    "resnet50_predictions = list(np.argmax(resnet50_predictions, axis=1))\n",
    "densenet_predictions = list(np.argmax(densenet_predictions, axis=1))\n",
    "NiN_predictions = list(np.argmax(NiN_predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = list(validation)\n",
    "lables = []\n",
    "for batch in validation_ds:\n",
    "    lables += list(np.argmax(batch[1], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_f1 = f1_score(y_true=lables, y_pred=vgg19_predictions, average='micro')\n",
    "print(f'{vgg19_f1*100:.2f}%')\n",
    "vgg19_conf_mat = confusion_matrix(lables, vgg19_predictions)\n",
    "vgg19_conf_disp = ConfusionMatrixDisplay(vgg19_conf_mat)\n",
    "vgg19_conf_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_f1 = f1_score(y_true=lables, y_pred=resnet50_predictions, average='micro')\n",
    "print(f'{resnet50_f1*100:.2f}%')\n",
    "resnet50_conf_mat = confusion_matrix(lables, resnet50_predictions)\n",
    "resnet50_conf_disp = ConfusionMatrixDisplay(resnet50_conf_mat)\n",
    "resnet50_conf_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_f1 = f1_score(y_true=lables, y_pred=densenet_predictions, average='micro')\n",
    "print(f'{densenet_f1*100:.2f}%')\n",
    "densenet_conf_mat = confusion_matrix(lables, densenet_predictions)\n",
    "densenet_conf_disp = ConfusionMatrixDisplay(densenet_conf_mat)\n",
    "densenet_conf_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NiN_f1 = f1_score(y_true=lables, y_pred=NiN_predictions, average='micro')\n",
    "print(f'{NiN_f1*100:.2f}%')\n",
    "NiN_conf_mat = confusion_matrix(lables, NiN_predictions)\n",
    "NiN_conf_disp = ConfusionMatrixDisplay(NiN_conf_mat)\n",
    "NiN_conf_disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
