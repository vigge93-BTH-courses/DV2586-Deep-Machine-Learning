{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('generated_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(title='Plot of the data set', ylabel='Value ($^\\circ{}$C/psi/%)', xlabel='Data point index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temperature'].plot(title='Plot of temperature', xlabel='Data point index', ylabel='Temperature ($^\\circ{}$C)', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[df['temperature_status']=='normal'].index, df[df['temperature_status']=='normal']['temperature'], label='Normal')\n",
    "plt.scatter(df[df['temperature_status']!='normal'].index, df[df['temperature_status']!='normal']['temperature'], label='Anomalous')\n",
    "plt.title('Normal and anomalous temperature data points')\n",
    "plt.xlabel('Data point index')\n",
    "plt.ylabel('Temperature ($^\\circ{}$C)')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data using Min-Max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_scaler = MinMaxScaler()\n",
    "pressure_scaler = MinMaxScaler()\n",
    "humidity_scaler = MinMaxScaler()\n",
    "df_train['temperature_norm'] = temp_scaler.fit_transform(df_train[['temperature']])\n",
    "df_train['pressure_norm'] = pressure_scaler.fit_transform(df_train[['pressure']])\n",
    "df_train['humidity_norm'] = humidity_scaler.fit_transform(df_train[['humidity']])\n",
    "df_test['temperature_norm'] = temp_scaler.transform(df_test[['temperature']])\n",
    "df_test['pressure_norm'] = pressure_scaler.transform(df_test[['pressure']])\n",
    "df_test['humidity_norm'] = humidity_scaler.transform(df_test[['humidity']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into normal and anomalous data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_temp_normal = df_train[df_train['temperature_status'] == 'normal'][['timestamp', 'temperature', 'temperature_norm']]\n",
    "df_test_temp_normal = df_test[df_test['temperature_status'] == 'normal'][['timestamp', 'temperature', 'temperature_norm']]\n",
    "df_temp_anomal_low = df_test[(df_test['temperature_status'] != 'normal') & (df_test['temperature'] < 26)][['timestamp', 'temperature', 'temperature_norm']]\n",
    "df_temp_anomal_high = df_test[(df_test['temperature_status'] != 'normal') & (df_test['temperature'] > 26)][['timestamp', 'temperature', 'temperature_norm']]\n",
    "\n",
    "df_train_pressure_normal = df_train[df_train['pressure_status'] == 'normal'][['timestamp', 'pressure', 'pressure_norm']]\n",
    "df_test_pressure_normal = df_test[df_test['pressure_status'] == 'normal'][['timestamp', 'pressure', 'pressure_norm']]\n",
    "df_pressure_anomal_low = df_test[(df_test['pressure_status'] != 'normal') & (df_test['pressure'] < 100)][['timestamp', 'pressure', 'pressure_norm']]\n",
    "df_pressure_anomal_high = df_test[(df_test['pressure_status'] != 'normal') & (df_test['pressure'] > 100)][['timestamp', 'pressure', 'pressure_norm']]\n",
    "\n",
    "df_train_humidity_normal = df_train[df_train['humidity_status'] == 'normal'][['timestamp', 'humidity', 'humidity_norm']]\n",
    "df_test_humidity_normal = df_test[df_test['humidity_status'] == 'normal'][['timestamp', 'humidity', 'humidity_norm']]\n",
    "df_humidity_anomal_low = df_test[(df_test['humidity_status'] != 'normal') & (df_test['humidity'] < 66)][['timestamp', 'humidity', 'humidity_norm']]\n",
    "df_humidity_anomal_high = df_test[(df_test['humidity_status'] != 'normal') & (df_test['humidity'] > 66)][['timestamp', 'humidity', 'humidity_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_anomal_high.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide datasets into signals with length defined by lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_input(df):\n",
    "    t = np.array(df)\n",
    "    X = []\n",
    "    for i in range(len(t) - lookback):\n",
    "        tX = []\n",
    "        for j in range(i, i+lookback):\n",
    "            tX.append([t[j]])\n",
    "        X.append(tX)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_to_input(df_train_temp_normal['temperature_norm'])\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(lookback,1))\n",
    "    # Encoder\n",
    "    x = LSTM(8, activation='relu', input_shape=(lookback, 1), return_sequences=True)(inp)\n",
    "    x = LSTM(4, activation='relu', return_sequences=False)(x)\n",
    "    # Decoder\n",
    "    x = RepeatVector(lookback)(x)\n",
    "    x = LSTM(4, activation='relu', return_sequences=True)(x)\n",
    "    x = LSTM(8, activation='relu', return_sequences=True)(x)\n",
    "    x = TimeDistributed(Dense(1))(x)\n",
    "    model = models.Model(\n",
    "        inputs = inp,\n",
    "        outputs=x\n",
    "    )\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = df_to_input(df_test_temp_normal['temperature_norm'])\n",
    "history = model.fit(x=X, y=X, epochs=100, validation_data=(validation, validation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model with good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model/8_4_96.6')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and metrics for the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Training and validation loss for LSTM Autoencoder')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.legend()\n",
    "plt.title('Training and validation Mean Absolute Error for LSTM Autoencoder')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "losses = tf.keras.losses.mae(predictions, X)\n",
    "mean, std = np.mean(losses), np.std(losses)\n",
    "threshold = mean + std*1\n",
    "print(f'{mean=}, {std=}, {threshold=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, threshold=threshold):\n",
    "    X = df_to_input(X)\n",
    "    predictions = model.predict(X, verbose=0)\n",
    "    test_losses = tf.keras.losses.mae(predictions, X)\n",
    "    test_loss = np.mean(test_losses, axis=1)\n",
    "    normal, anomaly = len(test_loss[test_loss <= threshold]), len(test_loss[test_loss > threshold])\n",
    "    return {'normal': normal, 'anomaly': anomaly, 'mean': np.mean(test_loss), 'std': np.std(test_loss)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = evaluate(df_test_temp_normal['temperature_norm'], threshold)\n",
    "high = evaluate(df_temp_anomal_high['temperature_norm'], threshold)\n",
    "low = evaluate(df_temp_anomal_low['temperature_norm'], threshold)\n",
    "TN = norm['normal']\n",
    "TP =  high['anomaly'] + low['anomaly']\n",
    "FN =  + high['normal'] + low['normal']\n",
    "FP = norm['anomaly']\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "F1 = 2*precision * recall / (precision + recall)\n",
    "print(f'{TP=}, {TN=}, {FP=}, {FN=}, {accuracy=:.4f}, {precision=:.4f}, {recall=:.3f}, {F1=:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = evaluate(df_test_pressure_normal['pressure_norm'], threshold)\n",
    "high = evaluate(df_pressure_anomal_high['pressure_norm'], threshold)\n",
    "low = evaluate(df_pressure_anomal_low['pressure_norm'], threshold)\n",
    "TN = norm['normal']\n",
    "TP =  high['anomaly'] + low['anomaly']\n",
    "FN =  + high['normal'] + low['normal']\n",
    "FP = norm['anomaly']\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "F1 = 2*precision * recall / (precision + recall)\n",
    "print(f'{TP=}, {TN=}, {FP=}, {FN=}, {accuracy=:.4f}, {precision=:.4f}, {recall=:.3f}, {F1=:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = evaluate(df_test_humidity_normal['humidity_norm'], threshold)\n",
    "high = evaluate(df_humidity_anomal_high['humidity_norm'], threshold)\n",
    "low = evaluate(df_humidity_anomal_low['humidity_norm'], threshold)\n",
    "TN = norm['normal']\n",
    "TP =  high['anomaly'] + low['anomaly']\n",
    "FN =  + high['normal'] + low['normal']\n",
    "FP = norm['anomaly']\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "F1 = 2*precision * recall / (precision + recall)\n",
    "print(f'{TP=}, {TN=}, {FP=}, {FN=}, {accuracy=:.4f}, {precision=:.4f}, {recall=:.3f}, {F1=:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
